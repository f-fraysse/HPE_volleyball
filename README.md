# HPE_volleyball

This project combines object detection, multi-object tracking, and pose estimation to analyze volleyball training sessions. It uses a customized version of [ByteTrack](https://github.com/ifzhang/ByteTrack) and RTMPose (through [RTMlib](https://github.com/Tau-J/rtmlib)) for tracking and pose analysis of players during spiking actions.

ğŸ‘‰ You can download pre-trained RTMDet and RTMPose ONNX models from [OpenMMLab Deploee](https://platform.openmmlab.com/deploee)

â— Still in very early stages â—

ğŸ’¹ Detection with RTMdet, trackin with Bytetrack, pose estimation with RTMPose
ğŸ’¹ Save output video with bboxes and poses overlay
âŒ Spike detection from pose data + some heuristics (to start with)
âŒ Edit tracked IDs manually (delete unused IDs, "relabel" IDs)
âŒ Interpolation / smoothing/ manual editing of keypoints
âŒ Performance optimisations

## ğŸ¥ Demo

https://github.com/user-attachments/assets/3a20771c-83d7-40c8-b43a-f9a36d718dc5

## ğŸ“ Project Structure

```
HPE_volleyball/
â”œâ”€â”€ ByteTrack/           # Forked + modified ByteTrack repo (tracking)
â”œâ”€â”€ models/              # RTMPose model weights, ONNX files, etc.
â”œâ”€â”€ data/                # Input videos for processing
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ h5/              # HDF5 outputs: poses, IDs, bboxes, scores
â”‚   â””â”€â”€ video/           # Output videos with overlays
â”œâ”€â”€ scripts/             # Custom scripts (main pipeline, helpers)
â”œâ”€â”€ paths.py             # Project-relative path definitions
â””â”€â”€ requirements.txt     # Python dependencies
```

## ğŸ”§ Prerequisites

To run inference on GPU, make sure the following are properly installed:

- **CUDA Toolkit** (e.g. CUDA 11.8 or compatible with your PyTorch version)
- **cuDNN** (compatible with your CUDA version)

## âš™ï¸ Setup

1. **Clone this repo**
   ```bash
   git clone https://github.com/yourusername/HPE_volleyball.git
   cd HPE_volleyball
   ```

2. **Set up environment**
   ```bash
   pip install -r requirements.txt
   ```

3. **Install ByteTrack**
   ```bash
   cd ByteTrack
   pip install -e .
   cd ..
   ```

4. (Optional) Ensure output folders are created:
   ```python
   from scripts.paths import ensure_output_dirs
   ensure_output_dirs()
   ```

## ğŸš€ Running the Pipeline

Work in progress â€” main script(s) will be located in `scripts/`.

1. add your input video to /data
2. add your ONNX models to /models :
      - download ONNX models from OpenMMLab Deployee: https://platform.openmmlab.com/deploee 
      - RTMDet model for detection
      - RTMPose model for pose estimation
3. run scripts/MAIN.py, the start of the script has config options
4. video file with overlaid bboxes, IDs, bbox scores and poses saved in output/video
5. HDF5 file with tracked IDs, bboxes and scores, keypoints and scores saved in output/h5

## ğŸ“¦ Dependencies

All Python packages are listed in `requirements.txt`.

GPU inference requires a working CUDA installation compatible with your PyTorch/ONNX versions

## ğŸ“„ Notes

- ByteTrack has been modified (e.g. fixed deprecated NumPy types).
- All paths are defined relative to the project root via `paths.py`.

## âœï¸ Author

Francois Fraysse â€” [frayssfe@gmail.com]

Thanks and credits to:  
- MMPose project - [https://github.com/open-mmlab/mmpose]
- RTMlib - [https://github.com/Tau-J/rtmlib]
- ByteTrack - [https://github.com/ifzhang/ByteTrack]

### ğŸ“š Licensing

This project is licensed under the [Apache 2.0 License](LICENSE).

It includes:
- [ByteTrack](https://github.com/ifzhang/ByteTrack) (MIT License) â€“ see `ByteTrack/LICENSE`
- [RTMLib](https://github.com/open-mmlab/rtmlib) (Apache 2.0 License)
