# ğŸƒâ€â™‚ï¸ HPE_volleyball Inference Optimization Guide

This document summarizes performance profiling and actionable steps to improve per-frame processing speed without sacrificing model quality.

---

## â±ï¸ Current Per-frame Timings

| Step        | Time   | Notes |
|-------------|--------|-------|
| Capture     | 6 ms   | âœ… negligible
| Detection   | 110 ms | ğŸ”´ bottleneck #1
| Tracking    | <1 ms  | âœ… super fast (ByteTrack is efficient)
| Pose        | 75 ms  | ğŸ”´ bottleneck #2
| Display     | <1 ms  | âœ… negligible

> **Detection + Pose = ~185 ms/frame** â†’ ~5.4 FPS

---

## ğŸ” Can We Improve Performance Without Degrading Model Quality?

Yes â€” here are several optimization strategies, ranked by difficulty and impact.

---

## âœ… 1. Run Detection Less Often (Easy, Big Win)

Run detection every **N frames** (e.g., every 3â€“5), and track forward in between.

```python
if frame_idx % DETECTION_INTERVAL == 0:
    detections = detector(frame)
    tracker.reset_with_detections(detections)
else:
    tracker.update(frame_only=True)  # skip detection
```

âœ… Big performance gain  
ğŸŸ¡ Slight accuracy tradeoff  
âœ… Works with your current models

---

## âœ… 2. Use Pose Estimation Only for Tracked Boxes

Ensure pose estimation is **only run on active tracked boxes**, not all detections or the full frame.

âœ… Efficient  
âœ… Likely already in place

---

## âœ… 3. Batch Pose Inference (Medium)

Batch all pose inputs into a single ONNX call:

```python
pose_inputs = [crop_and_preprocess(bbox) for bbox in tracked_bboxes]
pose_outputs = pose_model(pose_inputs)
```

âœ… Great GPU performance  
ğŸŸ¡ Needs refactor of pose code

---

## âœ… 4. Enable ONNX Runtime Graph Optimization (Easy)

Set this when creating the ONNX Runtime session:

```python
options = ort.SessionOptions()
options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
```

âœ… Free performance gain

---

## âœ… 5. Try Model Quantization (FP16 or INT8)

Convert RTMPose or RTMDet to **FP16 ONNX** for faster GPU inference.

Tools:
- `onnxruntime-tools`
- `onnxsim`
- `onnxconverter-common`

ğŸŸ  Needs validation for accuracy  
ğŸŸ¡ Medium complexity  
âœ… Can yield ~2Ã— speedup

---

## ğŸ§  Summary of Low-Hanging Fruit

| Tactic                           | Effort | Gain     |
|----------------------------------|--------|----------|
| ğŸ” Run detection every N frames  | ğŸŸ¢ Low  | ğŸŸ¢ Big    |
| ğŸ§  Batch pose estimation         | ğŸŸ¡ Med  | ğŸŸ¢ Big    |
| âš™ï¸ Optimize ONNX session         | ğŸŸ¢ Low  | ğŸŸ¡ Modest |
| ğŸ§Š Use FP16 ONNX models          | ğŸŸ  Med  | ğŸŸ¢ Big    |

---

## âœ… Ready to Implement?

Let me know if you want help with:

- Skipping detection frames
- Batchifying pose input
- ONNX quantization to FP16
- Benchmarking before/after

